{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T18:54:43.126791Z",
     "start_time": "2017-11-13T18:54:42.720304Z"
    },
    "code_folding": [
     38,
     52,
     60,
     90
    ]
   },
   "outputs": [],
   "source": [
    "# Class Neural Network\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, inputs_nodes, hidden_nodes, outputs_nodes, learning_rating):\n",
    "        self.input_nodes = inputs_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = outputs_nodes\n",
    "        self.lr = learning_rating\n",
    "        self.bias = 0\n",
    "        \n",
    "        self.nscale = 1 / self.input_nodes ** (-0.5)\n",
    "        self.w12 = np.random.normal(scale = self.nscale, size = ((self.input_nodes + self.bias), self.hidden_nodes))\n",
    "        self.w23 = np.random.normal(scale = self.nscale, size = ((self.hidden_nodes + self.bias), self.output_nodes))\n",
    "        \n",
    "        sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "        deriv_sigmoid = lambda x: (1 / (1 + np.exp(-x)))*(1 - 1 / ((1 + np.exp(-x))))\n",
    "        \n",
    "        self.activation_function = sigmoid\n",
    "        self.deriv_activation_function = deriv_sigmoid\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def feedforward_bias(self, x):\n",
    "        print('x', x.shape)\n",
    "        x = np.append(x, 1) # use of bias\n",
    "        print('x', x.shape)\n",
    "        print('w12', self.w12.shape)\n",
    "        phi12 = self.activation_function(np.dot(x, self.w12))\n",
    "        print('phi12', phi12.shape)\n",
    "        \n",
    "        phi12 = np.append(phi12, 1) # use of bias\n",
    "        print('phi12', phi12.shape)\n",
    "        dphi12 = self.deriv_activation_function(np.dot(x, self.w12))\n",
    "        print('dphi12', dphi12.shape)\n",
    "        dphi12 = np.append(dphi12, 1)\n",
    "        \n",
    "        output, doutput = self.activation_function(np.dot(phi12, self.w23)), 1\n",
    "        return phi12, dphi12, output, doutput\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def feedforward(self, x):\n",
    "        phi12 = self.activation_function(np.dot(x, self.w12))\n",
    "        dphi12 = self.deriv_activation_function(np.dot(x, self.w12))\n",
    "        output = self.activation_function(np.dot(phi12, self.w23))\n",
    "        #doutput = self.deriv_activation_function(np.dot(phi12, self.w23)) # Classification\n",
    "        doutput = 1 # Regression\n",
    "        return phi12, dphi12, output, doutput\n",
    "    \n",
    "    def backforward(self, x, phi12, dphi12, output, doutput, error):\n",
    "        output_error_term = error * doutput\n",
    "        hidden_error = np.dot(self.w23, output_error_term)\n",
    "        hidden_error_term = hidden_error * dphi12\n",
    "        return output_error_term, hidden_error_term\n",
    "    \n",
    "    def update_weights(self, x, phi12, output_error_term, hidden_error_term, dw12, dw23):\n",
    "        dw12 += hidden_error_term*x[:, None]\n",
    "        dw23 += output_error_term*phi12[:, None]\n",
    "        \n",
    "        self.w12 += self.lr*dw12/features.shape[0]\n",
    "        self.w23 += self.lr*dw23/features.shape[0]\n",
    "        return None\n",
    "    \n",
    "    def shuffle_data(self, features, targets):\n",
    "        df1 = pd.DataFrame(features)\n",
    "        df2 = pd.DataFrame(targets)\n",
    "        df = pd.concat([df1, df2], axis = 1)\n",
    "        df = df.sample(frac = 1)\n",
    "    \n",
    "        features = df.iloc[:, :features.shape[1]].values\n",
    "        targets = df.iloc[:, features.shape[1]:].values\n",
    "        return features, targets  \n",
    "\n",
    "    def train(self, features, targets, epochs):\n",
    "        for e in range(epochs):\n",
    "            features, targets = self.shuffle_data(features, targets)\n",
    "            error_rms, dw12, dw23 = 0, np.zeros(self.w12.shape), np.zeros(self.w23.shape) \n",
    "            for x, y in zip(features, targets):\n",
    "            \n",
    "                phi12, dphi12, output, doutput = self.feedforward(x)\n",
    "            \n",
    "                error = y - output\n",
    "            \n",
    "                output_error_term, hidden_error_term = self.backforward(x, phi12, dphi12, output, doutput, error)\n",
    "            \n",
    "                self.update_weights(x, phi12, output_error_term, hidden_error_term, dw12, dw23)\n",
    "                \n",
    "                error_rms += np.mean(error**2)\n",
    "                \n",
    "            Total_error = error_rms/(2 * features.shape[0])\n",
    "            \n",
    "        print(Total_error)\n",
    "        \n",
    "    def run(self, features_run):\n",
    "        aoutput = []\n",
    "        for x in features_run:\n",
    "            phi12, dphi12, output, doutput = self.feedforward(x)\n",
    "            \n",
    "            aoutput = np.append(aoutput, output)\n",
    "        return aoutput\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T19:00:42.449674Z",
     "start_time": "2017-11-13T19:00:42.410583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (3,)\n",
      "x (4,)\n",
      "w12 (4, 2)\n",
      "phi12 (2,)\n",
      "phi12 (3,)\n",
      "dphi12 (2,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,2) (3,3) (4,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-5bd332071823>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mhidden_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-19e5a53014bb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, features, targets, epochs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0moutput_error_term\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_error_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdphi12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_error_term\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_error_term\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdw12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdw23\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0merror_rms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-19e5a53014bb>\u001b[0m in \u001b[0;36mupdate_weights\u001b[0;34m(self, x, phi12, output_error_term, hidden_error_term, dw12, dw23)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphi12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_error_term\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_error_term\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdw12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdw23\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mdw12\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mhidden_error_term\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mdw23\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0moutput_error_term\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mphi12\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,2) (3,3) (4,2) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "#features = np.random.rand(5, 3)\n",
    "#targets = np.random.rand(5, 2)\n",
    "\n",
    "features = np.random.rand(5, 1)\n",
    "targets = features**2\n",
    "\n",
    "hidden_nodes, learning_rate, epochs = 2, 0.01, 2\n",
    "nn = NeuralNetwork(features.shape[1], hidden_nodes, targets.shape[1], learning_rate)\n",
    "nn.train(features, targets, epochs)\n",
    "\n",
    "\n",
    "#plt.scatter(features, targets)\n",
    "#plt.scatter(features, nn.run(features))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
