{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-19T17:12:24.069752Z",
     "start_time": "2017-11-19T17:12:16.149012Z"
    },
    "code_folding": [
     1,
     2,
     29,
     39,
     45,
     55,
     64,
     72,
     89,
     113,
     122,
     170,
     201,
     211,
     223,
     233,
     255,
     264,
     292,
     312,
     342,
     351,
     356,
     362,
     374,
     384,
     405,
     407
    ]
   },
   "outputs": [],
   "source": [
    "# Class Neural Network with one hidden layer\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, inputs_nodes, hidden_nodes, outputs_nodes, learning_rating, bias):\n",
    "        self.input_nodes = inputs_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = outputs_nodes\n",
    "        self.lr = learning_rating\n",
    "        self.bias = bias\n",
    "        \n",
    "        np.random.seed()\n",
    "        \n",
    "        self.nscale = 1 / self.input_nodes ** (-0.5)\n",
    "        self.w12 = np.random.normal(scale = self.nscale, size = (self.input_nodes, self.hidden_nodes))\n",
    "        self.w23 = np.random.normal(scale = self.nscale, size = (self.hidden_nodes, self.output_nodes))\n",
    "        self.b12 = np.random.normal(scale = self.nscale, size = (1, self.hidden_nodes))\n",
    "        self.b23 = np.random.normal(scale = self.nscale, size = (1, self.output_nodes))\n",
    "        \n",
    "        sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "        deriv_sigmoid = lambda x: (1 / (1 + np.exp(-x)))*(1 - 1 / ((1 + np.exp(-x))))\n",
    "        \n",
    "        linear = lambda x: x\n",
    "        deriv_linear = lambda x: 1\n",
    "        \n",
    "        self.act_func = sigmoid\n",
    "        self.deriv_act_func = deriv_sigmoid\n",
    "        \n",
    "        self.act_func_out = linear\n",
    "        self.deriv_act_func_out = deriv_linear\n",
    "    \n",
    "    def show_fdebug(self, x, phi12, output):            \n",
    "        print('w12', self.w12.shape)\n",
    "        print('w23', self.w23.shape)\n",
    "        print('w23_wo_bias')\n",
    "        print('np.append(x, self.bias)', np.append(x, self.bias).shape)\n",
    "        print('phi12', phi12.shape)\n",
    "        print('output', output.shape)\n",
    "        print('b12', self.b12.shape)\n",
    "        print('b23', self.b23.shape)\n",
    "        return None     \n",
    "    def show_bdebug(self, hidden_error, output_error_term, hidden_error_term):\n",
    "        print('hidden_error', hidden_error.shape)\n",
    "        print('output_error_term', output_error_term.shape)\n",
    "        print('hidden_error_term', hidden_error_term.shape)\n",
    "        return None    \n",
    "            \n",
    "    def shuffle_data(self, features, targets):\n",
    "        df1 = pd.DataFrame(features)\n",
    "        df2 = pd.DataFrame(targets)\n",
    "        df = pd.concat([df1, df2], axis = 1)\n",
    "        df = df.sample(frac = 1)\n",
    "    \n",
    "        features = df.iloc[:, :features.shape[1]].values\n",
    "        targets = df.iloc[:, features.shape[1]:].values\n",
    "        return features, targets  \n",
    "   \n",
    "    def feedforward(self, x): \n",
    "        \n",
    "        phi12 = self.act_func(np.dot(x, self.w12) + (self.bias * self.b12))\n",
    "        dphi12 = self.deriv_act_func(np.dot(x, self.w12) + (self.bias * self.b12))\n",
    "        output = self.act_func_out(np.dot(phi12, self.w23) + (self.bias * self.b23))\n",
    "        doutput = self.deriv_act_func_out(np.dot(phi12, self.w23) + (self.bias * self.b23))\n",
    "\n",
    "        #self.show_fdebug(x, phi12, output)\n",
    "        return phi12, dphi12, output, doutput\n",
    "    def backforward(self, phi12, dphi12, output, doutput, error):\n",
    "        \n",
    "        output_error_term = error * doutput\n",
    "        hidden_error = np.dot(output_error_term, self.w23.T)\n",
    "        hidden_error_term = hidden_error * dphi12\n",
    "        \n",
    "        #self.show_bdebug(hidden_error, output_error_term, hidden_error_term)\n",
    "        return output_error_term, hidden_error_term   \n",
    "    def update_weights(self, x, phi12, output_error_term, hidden_error_term, dw12, dw23, db12, db23):\n",
    "        \n",
    "        dw12 += hidden_error_term*x.reshape(self.input_nodes, 1)\n",
    "        dw23 += output_error_term*phi12.reshape(self.hidden_nodes, 1)\n",
    "        \n",
    "        self.w12 += self.lr*dw12/self.input_nodes\n",
    "        self.w23 += self.lr*dw23/self.input_nodes\n",
    "        \n",
    "        \n",
    "        db12 += hidden_error_term*self.bias\n",
    "        db23 += output_error_term*self.bias\n",
    "        \n",
    "        self.b12 += self.lr*db12/self.input_nodes\n",
    "        self.b23 += self.lr*db23/self.input_nodes\n",
    "        \n",
    "        return None\n",
    "  \n",
    "    def train(self, features, targets, epochs):\n",
    "        Total_error_vector = []\n",
    "        for e in range(epochs):\n",
    "            features, targets = self.shuffle_data(features, targets)\n",
    "            error_rms = 0\n",
    "            dw12, dw23 = np.zeros(self.w12.shape), np.zeros(self.w23.shape) \n",
    "            db12, db23 = np.zeros(self.b12.shape), np.zeros(self.b23.shape)\n",
    "            for x, y in zip(features, targets):\n",
    "            \n",
    "                phi12, dphi12, output, doutput = self.feedforward(x)\n",
    "            \n",
    "                error = y - output\n",
    "            \n",
    "                output_error_term, hidden_error_term = self.backforward(phi12, dphi12, output, doutput, error)\n",
    "            \n",
    "                self.update_weights(x, phi12, output_error_term, hidden_error_term, dw12, dw23, db12, db23)\n",
    "                \n",
    "                error_rms += np.mean(error**2)\n",
    "                \n",
    "            Total_error = error_rms/(2 * features.shape[0])\n",
    "            \n",
    "            Total_error_vector.append(Total_error)\n",
    "            \n",
    "        return Total_error_vector\n",
    "    def run(self, features_test):\n",
    "        aoutput = []\n",
    "        for x in features_test:\n",
    "            phi12, dphi12, output, doutput = self.feedforward(x)\n",
    "            \n",
    "            aoutput = np.append(aoutput, output)\n",
    "            \n",
    "        return aoutput\n",
    "    \n",
    "    def train_validation(self, features_train, targets_train, features_test, targets_test, epochs):\n",
    "        Total_error_vector, Total_error_tv_vector = [], []\n",
    "        for e in range(epochs):\n",
    "            features_train, targets_train = self.shuffle_data(features_train, targets_train)\n",
    "            features_test, targets_test = self.shuffle_data(features_test, targets_test)\n",
    "            error_rms, error_tv_rms = 0, 0\n",
    "            dw12, dw23 = np.zeros(self.w12.shape), np.zeros(self.w23.shape)\n",
    "            db12, db23 = np.zeros(self.b12.shape), np.zeros(self.b23.shape)\n",
    "            \n",
    "            for x, y in zip(features_train, targets_train):\n",
    "            \n",
    "                phi12, dphi12, output, doutput = self.feedforward(x)\n",
    "            \n",
    "                error = y - output\n",
    "            \n",
    "                output_error_term, hidden_error_term = self.backforward(phi12, dphi12, output, doutput, error)\n",
    "            \n",
    "                self.update_weights(x, phi12, output_error_term, hidden_error_term, dw12, dw23, db12, db23)\n",
    "                \n",
    "                error_rms += np.mean(error**2)\n",
    "                \n",
    "            Total_error = error_rms/(2 * features_train.shape[0])\n",
    "            \n",
    "            Total_error_vector.append(Total_error)\n",
    "            \n",
    "            \n",
    "            for x, y in zip(features_test, targets_test):\n",
    "                \n",
    "                error_tv = self.run(features_test) - targets_test\n",
    "                \n",
    "                error_tv_rms += np.mean(error_tv**2)\n",
    "                \n",
    "            Total_error_tv = error_tv_rms/(2 * features_test.shape[0])\n",
    "            \n",
    "            Total_error_tv_vector.append(Total_error_tv)\n",
    "            \n",
    "            \n",
    "            progress = 100 * e/float(epochs)\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress: {:2.1f}\".format(progress) + \"% \" \\\n",
    "                             + \"     Total Error on trainning: \" + str(Total_error))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        return Total_error_vector, Total_error_tv_vector\n",
    "    \n",
    "    \n",
    "    \n",
    "# Class Neural Network with two hidden layers\n",
    "class MultiLayerPerceptron_old:\n",
    "    def __init__(self, inputs_nodes, hidden_nodes, outputs_nodes, learning_rating, bias):\n",
    "        self.input_nodes = inputs_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = outputs_nodes\n",
    "        self.lr = learning_rating\n",
    "        self.bias = bias\n",
    "        \n",
    "        np.random.seed()\n",
    "        \n",
    "        self.nscale = 1 / self.input_nodes ** (-0.5)\n",
    "        self.w12 = np.random.normal(scale = self.nscale, size = (self.input_nodes, self.hidden_nodes))\n",
    "        self.w23 = np.random.normal(scale = self.nscale, size = (self.hidden_nodes, self.hidden_nodes))\n",
    "        self.w34 = np.random.normal(scale = self.nscale, size = (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        self.b12 = np.random.normal(scale = self.nscale, size = (1, self.hidden_nodes))\n",
    "        self.b23 = np.random.normal(scale = self.nscale, size = (1, self.hidden_nodes))\n",
    "        self.b34 = np.random.normal(scale = self.nscale, size = (1, self.output_nodes))\n",
    "        \n",
    "        sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "        deriv_sigmoid = lambda x: (1 / (1 + np.exp(-x)))*(1 - 1 / ((1 + np.exp(-x))))\n",
    "        \n",
    "        linear = lambda x: x\n",
    "        deriv_linear = lambda x: 1\n",
    "        \n",
    "        self.act_func = sigmoid\n",
    "        self.deriv_act_func = deriv_sigmoid\n",
    "        \n",
    "        self.act_func_out = linear\n",
    "        self.deriv_act_func_out = deriv_linear\n",
    "            \n",
    "    def shuffle_data(self, features, targets):\n",
    "        df1 = pd.DataFrame(features)\n",
    "        df2 = pd.DataFrame(targets)\n",
    "        df = pd.concat([df1, df2], axis = 1)\n",
    "        df = df.sample(frac = 1)\n",
    "    \n",
    "        features = df.iloc[:, :features.shape[1]].values\n",
    "        targets = df.iloc[:, features.shape[1]:].values\n",
    "        return features, targets  \n",
    "   \n",
    "    def feedforward(self, x): \n",
    "        \n",
    "        phi12 = self.act_func(np.dot(x, self.w12) + (self.bias * self.b12))\n",
    "        dphi12 = self.deriv_act_func(np.dot(x, self.w12) + (self.bias * self.b12))\n",
    "        \n",
    "        phi23 = self.act_func(np.dot(phi12, self.w23) + (self.bias * self.b23))\n",
    "        dphi23 = self.deriv_act_func(np.dot(phi12, self.w23) + (self.bias * self.b23))\n",
    "        \n",
    "        output = self.act_func_out(np.dot(phi23, self.w34) + (self.bias * self.b34))\n",
    "        doutput = self.deriv_act_func_out(np.dot(phi23, self.w34) + (self.bias * self.b34))\n",
    "\n",
    "        return phi12, dphi12, phi23, dphi23, output, doutput\n",
    "    def backforward(self, phi12, dphi12, phi23, dphi23, output, doutput, error):\n",
    "        \n",
    "        output_error_term = error * doutput\n",
    "        hidden_error23 = np.dot(output_error_term, self.w34.T)\n",
    "        hidden_error_term23 = hidden_error23 * dphi23\n",
    "        \n",
    "        hidden_error12 = np.dot(hidden_error_term23, self.w23.T)\n",
    "        hidden_error_term12 = hidden_error12 *dphi12\n",
    "        \n",
    "        return output_error_term, hidden_error_term23, hidden_error_term12   \n",
    "    def update_weights(self, x, phi12, phi23, output_error_term,\n",
    "                                    hidden_error_term23, hidden_error_term12, dw12, dw23, dw34, db12, db23, db34):\n",
    "        \n",
    "        dw12 += hidden_error_term12*x.reshape(self.input_nodes, 1)\n",
    "        dw23 += hidden_error_term23*phi12.reshape(self.hidden_nodes, 1)\n",
    "        dw34 += output_error_term*phi23.reshape(self.hidden_nodes, 1)\n",
    "        \n",
    "        self.w12 += self.lr*dw12/self.input_nodes\n",
    "        self.w23 += self.lr*dw23/self.input_nodes\n",
    "        self.w34 += self.lr*dw34/self.input_nodes\n",
    "        \n",
    "        \n",
    "        db12 += hidden_error_term12*self.bias\n",
    "        db23 += hidden_error_term23*self.bias\n",
    "        db34 += output_error_term*self.bias\n",
    "        \n",
    "        self.b12 += self.lr*db12/self.input_nodes\n",
    "        self.b23 += self.lr*db23/self.input_nodes\n",
    "        self.b34 += self.lr*db34/self.input_nodes\n",
    "        \n",
    "        return None\n",
    "  \n",
    "    def run(self, features_test):\n",
    "        aoutput = []\n",
    "        for x in features_test:\n",
    "            phi12, dphi12, phi23, dphi23, output, doutput = self.feedforward(x)\n",
    "            \n",
    "            aoutput = np.append(aoutput, output)\n",
    "            \n",
    "        return aoutput\n",
    "    \n",
    "    def train_validation(self, features_train, targets_train, features_test, targets_test, epochs):\n",
    "        Total_error_vector, Total_error_tv_vector = [], []\n",
    "        for e in range(epochs):\n",
    "            features_train, targets_train = self.shuffle_data(features_train, targets_train)\n",
    "            features_test, targets_test = self.shuffle_data(features_test, targets_test)\n",
    "            error_rms, error_tv_rms = 0, 0\n",
    "            dw12, dw23, dw34 = np.zeros(self.w12.shape), np.zeros(self.w23.shape), np.zeros(self.w34.shape)\n",
    "            db12, db23, db34 = np.zeros(self.b12.shape), np.zeros(self.b23.shape), np.zeros(self.b34.shape)\n",
    "            \n",
    "            for x, y in zip(features_train, targets_train):\n",
    "            \n",
    "                phi12, dphi12, phi23, dphi23, output, doutput = self.feedforward(x)\n",
    "            \n",
    "                error = y - output\n",
    "            \n",
    "                output_error_term, hidden_error_term23, hidden_error_term12 = self.backforward(phi12,\n",
    "                                                                        dphi12, phi23, dphi23, output, doutput, error)\n",
    "            \n",
    "                self.update_weights(x, phi12, phi23, output_error_term,\n",
    "                                    hidden_error_term23, hidden_error_term12, dw12, dw23, dw34, db12, db23, db34)\n",
    "                \n",
    "                error_rms += np.mean(error**2)\n",
    "                \n",
    "            Total_error = error_rms/(2 * features_train.shape[0])\n",
    "            \n",
    "            Total_error_vector.append(Total_error)\n",
    "            \n",
    "            \n",
    "            for x, y in zip(features_test, targets_test):\n",
    "                \n",
    "                error_tv = self.run(features_test) - targets_test\n",
    "                \n",
    "                error_tv_rms += np.mean(error_tv**2)\n",
    "                \n",
    "            Total_error_tv = error_tv_rms/(2 * features_test.shape[0])\n",
    "            \n",
    "            Total_error_tv_vector.append(Total_error_tv)\n",
    "            \n",
    "            \n",
    "            progress = 100 * e/float(epochs)\n",
    "            sys.stdout.write(\"\\rProgress: {:2.1f}\".format(progress) + \"% \")\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        print(Total_error)\n",
    "        return Total_error_vector, Total_error_tv_vector\n",
    "\n",
    "    \n",
    "class MultiLayerPerceptron:\n",
    "    def __init__(self, inputs_nodes, hidden_nodes, outputs_nodes, learning_rating, bias):\n",
    "        self.input_nodes = inputs_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = outputs_nodes\n",
    "        self.lr = learning_rating\n",
    "        self.bias = bias\n",
    "        \n",
    "        np.random.seed()\n",
    "        \n",
    "        self.nscale = 1 / self.input_nodes ** (-0.5)\n",
    "        self.w12 = np.random.normal(scale = self.nscale, size = (self.input_nodes, self.hidden_nodes))\n",
    "        self.w23 = np.random.normal(scale = self.nscale, size = (self.hidden_nodes, self.hidden_nodes))\n",
    "        self.w34 = np.random.normal(scale = self.nscale, size = (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        self.b12 = np.random.normal(scale = self.nscale, size = (1, self.hidden_nodes))\n",
    "        self.b23 = np.random.normal(scale = self.nscale, size = (1, self.hidden_nodes))\n",
    "        self.b34 = np.random.normal(scale = self.nscale, size = (1, self.output_nodes))\n",
    "        \n",
    "        sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "        deriv_sigmoid = lambda x: (1 / (1 + np.exp(-x)))*(1 - 1 / ((1 + np.exp(-x))))\n",
    "        \n",
    "        linear = lambda x: x\n",
    "        deriv_linear = lambda x: 1\n",
    "        \n",
    "        self.act_func = sigmoid\n",
    "        self.deriv_act_func = deriv_sigmoid\n",
    "        \n",
    "        self.act_func_out = linear\n",
    "        self.deriv_act_func_out = deriv_linear\n",
    "            \n",
    "    def shuffle_data(self, features, targets):\n",
    "        df1 = pd.DataFrame(features)\n",
    "        df2 = pd.DataFrame(targets)\n",
    "        df = pd.concat([df1, df2], axis = 1)\n",
    "        df = df.sample(frac = 1)\n",
    "    \n",
    "        features = df.iloc[:, :features.shape[1]].values\n",
    "        targets = df.iloc[:, features.shape[1]:].values\n",
    "        return features, targets  \n",
    "    def zeros(self):\n",
    "        self.error_rms, self.error_tv_rms = 0, 0\n",
    "        self.dw12, self.dw23, self.dw34 = np.zeros(self.w12.shape), np.zeros(self.w23.shape), np.zeros(self.w34.shape)\n",
    "        self.db12, self.db23, self.db34 = np.zeros(self.b12.shape), np.zeros(self.b23.shape), np.zeros(self.b34.shape)\n",
    "        return None\n",
    "    def progress(self, e, epochs):\n",
    "        progress = 100 * e/float(epochs)\n",
    "        sys.stdout.write(\"\\rProgress: {:2.1f}\".format(progress) + \"% \")\n",
    "        sys.stdout.flush()\n",
    "        return None\n",
    "\n",
    "    def feedforward(self, x): \n",
    "        \n",
    "        self.phi12 = self.act_func(np.dot(x, self.w12) + (self.bias * self.b12))\n",
    "        self.dphi12 = self.deriv_act_func(np.dot(x, self.w12) + (self.bias * self.b12))\n",
    "        \n",
    "        self.phi23 = self.act_func(np.dot(self.phi12, self.w23) + (self.bias * self.b23))\n",
    "        self.dphi23 = self.deriv_act_func(np.dot(self.phi12, self.w23) + (self.bias * self.b23))\n",
    "        \n",
    "        self.output = self.act_func_out(np.dot(self.phi23, self.w34) + (self.bias * self.b34))\n",
    "        self.doutput = self.deriv_act_func_out(np.dot(self.phi23, self.w34) + (self.bias * self.b34))\n",
    "\n",
    "        return None\n",
    "    def backforward(self):\n",
    "        \n",
    "        self.output_error_term = self.error * self.doutput\n",
    "        self.hidden_error23 = np.dot(self.output_error_term, self.w34.T)\n",
    "        self.hidden_error_term23 = self.hidden_error23 * self.dphi23\n",
    "        \n",
    "        self.hidden_error12 = np.dot(self.hidden_error_term23, self.w23.T)\n",
    "        self.hidden_error_term12 = self.hidden_error12 * self.dphi12\n",
    "        \n",
    "        return None   \n",
    "    def update_weights(self, x):\n",
    "        \n",
    "        self.dw12 += self.hidden_error_term12*x.reshape(self.input_nodes, 1)\n",
    "        self.dw23 += self.hidden_error_term23*self.phi12.reshape(self.hidden_nodes, 1)\n",
    "        self.dw34 += self.output_error_term*self.phi23.reshape(self.hidden_nodes, 1)\n",
    "        \n",
    "        self.w12 += self.lr*self.dw12/self.input_nodes\n",
    "        self.w23 += self.lr*self.dw23/self.input_nodes\n",
    "        self.w34 += self.lr*self.dw34/self.input_nodes\n",
    "        \n",
    "        \n",
    "        self.db12 += self.hidden_error_term12*self.bias\n",
    "        self.db23 += self.hidden_error_term23*self.bias\n",
    "        self.db34 += self.output_error_term*self.bias\n",
    "        \n",
    "        self.b12 += self.lr*self.db12/self.input_nodes\n",
    "        self.b23 += self.lr*self.db23/self.input_nodes\n",
    "        self.b34 += self.lr*self.db34/self.input_nodes\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def run(self, features_test):\n",
    "        aoutput = []\n",
    "        for x in features_test:\n",
    "            self.feedforward(x)\n",
    "            \n",
    "            aoutput = np.append(aoutput, self.output)\n",
    "            \n",
    "        return aoutput\n",
    "    \n",
    "    def train_validation(self, features_train, targets_train, features_test, targets_test, epochs):\n",
    "        Total_error_vector, Total_error_tv_vector = [], []\n",
    "        for e in range(epochs):\n",
    "            features_train, targets_train = self.shuffle_data(features_train, targets_train)\n",
    "            features_test, targets_test   = self.shuffle_data(features_test,  targets_test)\n",
    "            self.zeros()\n",
    "            for x, y in zip(features_train, targets_train):\n",
    "            \n",
    "                self.feedforward(x)\n",
    "            \n",
    "                self.error = y - self.output\n",
    "            \n",
    "                self.backforward()\n",
    "            \n",
    "                self.update_weights(x)\n",
    "                \n",
    "                self.error_rms += np.mean(self.error**2)\n",
    "                \n",
    "            Total_error = self.error_rms/(2 * features_train.shape[0])\n",
    "            \n",
    "            Total_error_vector.append(Total_error)\n",
    "            \n",
    "            \n",
    "            for x, y in zip(features_test, targets_test):\n",
    "                \n",
    "                self.error_tv = self.run(features_test) - targets_test\n",
    "                \n",
    "                self.error_tv_rms += np.mean(self.error_tv**2)\n",
    "                \n",
    "            Total_error_tv = self.error_tv_rms/(2 * features_test.shape[0])\n",
    "            \n",
    "            Total_error_tv_vector.append(Total_error_tv)\n",
    "            \n",
    "            \n",
    "            self.progress(e, epochs)\n",
    "            \n",
    "        return Total_error_vector, Total_error_tv_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-19T17:12:24.319453Z",
     "start_time": "2017-11-19T17:12:24.072768Z"
    },
    "code_folding": [
     0,
     8,
     18,
     22,
     27,
     33,
     46
    ],
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_data(features, targets):\n",
    "    \n",
    "    n = np.round(0.7*features.shape[0]).astype(int)\n",
    "    \n",
    "    features_train, targets_train = features[:n], targets[:n]\n",
    "    features_test, targets_test = order_data(features[n:], targets[n:])\n",
    "    \n",
    "    return features_train, targets_train, features_test, targets_test\n",
    "def order_data(features, targets):\n",
    "    df1 = pd.DataFrame(features)\n",
    "    df2 = pd.DataFrame(targets)\n",
    "    df = pd.concat([df1, df2], axis = 1)\n",
    "    df.columns = ['0', '1']\n",
    "    df = df.sort_values(by = '0')\n",
    "    features = df.iloc[:, :features.shape[1]].values\n",
    "    targets = df.iloc[:, features.shape[1]:].values\n",
    "    return features, targets\n",
    "\n",
    "def hyper_static(n_features, n_targets):\n",
    "    hidden_nodes = round((n_features + n_targets)/2) + 1 \n",
    "    bias = -1\n",
    "    return hidden_nodes, bias\n",
    "def frd_features_targets(n_records, n_features, n_targets):\n",
    "    features = np.random.rand(n_records, n_features)\n",
    "    targets = np.random.rand(n_records, n_targets)\n",
    "    #features, targets = order_data(features, targets)\n",
    "    return features, targets\n",
    "def frd_targets(n_records, n_features):\n",
    "    features = np.random.rand(n_records, n_features)\n",
    "    #targets = features**2 + 0.2*features**2 - (features - 0.1)\n",
    "    #targets = (features**3)+(features**2)-features\n",
    "    targets = np.sin(features*6.28)\n",
    "    return features, targets\n",
    "def print_trainning_results(features_train, targets_train, features_test, aoutput, Total_error_vector, epochs):\n",
    "    plt.figure(1)\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "    n = np.round(0.2*epochs).astype(int)\n",
    "    plt.plot(range(epochs)[n:], Total_error_vector[n:])\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.scatter(features_train, targets_train)\n",
    "    plt.scatter(features_test, aoutput)\n",
    "        \n",
    "    return plt.show()\n",
    "def print_trainning_validation(Total_error_vector, Total_error_tv_vector, features_train,\n",
    "                               targets_train, features_test, aoutput, epochs):\n",
    "    plt.figure(1)\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    n = np.round(0.001*epochs).astype(int)\n",
    "    plt.plot(np.array(range(epochs))[n:], Total_error_vector[n:])\n",
    "    plt.plot(np.array(range(epochs))[n:], Total_error_tv_vector[n:])\n",
    "    plt.ylim(0, .5)\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.scatter(features_train, targets_train)\n",
    "    features_test, aoutput = order_data(features_test, aoutput)\n",
    "    plt.scatter(features_test, aoutput)\n",
    "    plt.ylim(-1, 1)\n",
    "    \n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-19T17:12:35.808043Z",
     "start_time": "2017-11-19T17:12:24.322286Z"
    },
    "code_folding": [
     7
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 99.9% "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD8CAYAAAB9y7/cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f89ca4fe8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "\n",
    "def main_network(learning_rate, epochs):\n",
    "    n_records, n_features, n_targets = 20, 1, 1\n",
    "\n",
    "    features, targets = frd_targets(n_records, n_features)\n",
    "    features_train, targets_train, features_test, targets_test = split_data(features, targets)\n",
    "\n",
    "    hidden_nodes, bias = hyper_static(features.shape[1], targets.shape[1])\n",
    "    nnx = NeuralNetwork(features.shape[1], hidden_nodes, targets.shape[1], learning_rate, bias)\n",
    "    nn = MultiLayerPerceptron(features.shape[1], hidden_nodes, targets.shape[1], learning_rate, bias)\n",
    "    \n",
    "    Total_error_vector, Total_error_tv_vector = nn.train_validation(\n",
    "                                                    features_train,targets_train, features_test, targets_test, epochs)\n",
    "    \n",
    "    print_trainning_validation(Total_error_vector, Total_error_tv_vector, features_train,\n",
    "                              targets_train, features_test, nn.run(features_test), epochs)\n",
    "\n",
    "    return None\n",
    "\n",
    "def main(loop = 3):\n",
    "    k = 1\n",
    "    for i in range(0, loop):\n",
    "        k *= 0.1\n",
    "        lr, epochs = 0.01, 1000\n",
    "        main_network(lr, epochs)\n",
    "        \n",
    "main(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
